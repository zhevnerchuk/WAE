{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from gan import GANWAE\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: /Users/zhevnerchuk/Desktop/BMML/project/MNIST\n",
       "    Transforms (if any): None\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.datasets.MNIST(\n",
    "    root='/Users/zhevnerchuk/Desktop/BMML/project/MNIST',\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('../MNIST',\n",
    "                               train=True, \n",
    "                               download=False,\n",
    "                               transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))]),\n",
    "                              ),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 1\n",
    "z_dim = 10\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(tuple([tensor.shape[0]] + self.size))\n",
    "\n",
    "encoder = nn.Sequential(\n",
    "            nn.Conv2d(nc, 128, 4, 2, 1, bias=False),              # B,  128, 32, 32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),             # B,  256, 16, 16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),             # B,  512,  8,  8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),            # B, 1024,  4,  4\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            View([-1]),                                 # B, 1024*4*4\n",
    "            nn.Linear(1024, z_dim)                            # B, z_dim\n",
    "        )\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1024*8*8),                           # B, 1024*8*8\n",
    "            View([1024, 8, 8]),                               # B, 1024,  8,  8\n",
    "            nn.ConvTranspose2d(1024, 512, 2, 2, 1, bias=False),   # B,  512, 16, 16\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 1, 1, bias=False),    # B,  256, 32, 32\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 28, 2, 2, 1, bias=False),    # B,  128, 64, 64\n",
    "            nn.BatchNorm2d(28),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(28, nc, 1),                       # B,   nc, 64, 64\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_latent_prior(batch_size):\n",
    "    return torch.normal(torch.zeros(batch_size, z_dim), torch.ones(batch_size, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(Y_true, Y_pred):\n",
    "    return torch.nn.functional.mse_loss(Y_pred, Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "    \"\"\"Adversary architecture(Discriminator) for WAE-GAN.\"\"\"\n",
    "    def __init__(self, z_dim=10):\n",
    "        super(Adversary, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 512),                                # B, 512\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),                                  # B, 512\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),                                  # B, 512\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),                                  # B, 512\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1),                                    # B,   1\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Divergence(object):\n",
    "    def __init__(self, adv, optim, lambda_coeff):\n",
    "        self.adv = adv\n",
    "        self.optim = optim\n",
    "        self.lambda_coeff = lambda_coeff\n",
    "        \n",
    "    def __call__(self, Z_prior, Z_conditional):\n",
    "        real = self.adv(Z_prior)\n",
    "        fake = self.adv(Z_conditional)\n",
    "        loss = self.lambda_coeff * (torch.sum(torch.log(real)) + torch.sum(torch.log(1 - fake)))\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.optim.step()\n",
    "        self.optim.zero_grad()\n",
    "        fake = torch.sum(torch.log(self.adv(Z_conditional)))\n",
    "        return fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\"+str(gpu_id) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = Adversary(z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_opt = optimizer = torch.optim.Adam(\n",
    "            adv.parameters(),\n",
    "            lr=1e-2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergence = Divergence(adv, adv_opt, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()),\n",
    "            lr=1e-2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GANWAE(cost=cost, decoder=decoder, encoder=encoder, device=device, lamda_coeff=0.1, divergence=divergence,\n",
    "       sample_latent_prior=sample_latent_prior, trainloader=train_loader, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-714e97d5ad58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/BMML/project/WAE/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epoches)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_term\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_coeff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_conditional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gan.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13653e1d0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample.data.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
