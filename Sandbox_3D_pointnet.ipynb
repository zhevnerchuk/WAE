{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from mmd_pointnet import MMDWAE\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Albert.Matveev/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch.utils.data as data\n",
    "\n",
    "class H5Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, sample_size = 1024):\n",
    "        super(H5Dataset, self).__init__()\n",
    "        self.sample_size = sample_size\n",
    "        random_index = np.random.choice(np.arange(10000), self.sample_size)\n",
    "        h5_file = h5py.File(file_path)\n",
    "        self.data = h5_file.get('data')\n",
    "        self.target = h5_file.get('data')\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):            \n",
    "        return (torch.from_numpy(self.data[index]).float(),\n",
    "                torch.from_numpy(self.target[index]).float())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = H5Dataset('modelnet_train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1024\n",
    "z_dim = 50\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "encoder = nn.Sequential(\n",
    "      nn.Conv1d(3, 64, 1),\n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm1d(64),\n",
    "      nn.Conv1d(64, 128, 1),\n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm1d(128),\n",
    "      nn.Conv1d(128, 256, 1),\n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm1d(256),\n",
    "      nn.Conv1d(256, 512, 1),\n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm1d(512),\n",
    "      nn.MaxPool1d(1024, 1),\n",
    "      View((-1,512)),\n",
    "      nn.Linear(512,50)\n",
    "    )\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "      nn.Linear(50,512),\n",
    "#       View((-1,1024,512)),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512,1024),\n",
    "      nn.Linear(1024, 2048),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(2048, 3*1024),\n",
    "      View((-1, 1024, 3))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(encoder(X[0:1].transpose(1,2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_latent_prior(batch_size):\n",
    "    return torch.normal(torch.zeros(batch_size, z_dim), torch.ones(batch_size, z_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(Y_true, Y_pred):\n",
    "    return torch.nn.functional.mse_loss(Y_pred, Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel(z1, z2):\n",
    "    z11 = z1.unsqueeze(1).repeat(1, z2.size(0), 1)\n",
    "    z22 = z2.unsqueeze(0).repeat(z1.size(0), 1, 1)\n",
    "    \n",
    "    C = 1\n",
    "\n",
    "    kernel_matrix = C/(1e-9+C+(z11-z22).pow(2).sum(2))\n",
    "    kernel_sum = kernel_matrix.sum()\n",
    "\n",
    "    return kernel_sum.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\"+str(1) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (3): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=2048, out_features=3072, bias=True)\n",
       "  (6): View()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()),\n",
    "            lr=1e-4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmd = MMDWAE(cost=cost, decoder=decoder, encoder=encoder, device=device, lamda_coeff=0.1, kernel=kernel,\n",
    "       sample_latent_prior=sample_latent_prior, trainloader=train_loader, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Albert.Matveev/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/Albert.Matveev/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py\", line 63, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/Albert.Matveev/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 500/500 [1:58:05<00:00, 14.17s/it]\n"
     ]
    }
   ],
   "source": [
    "mmd.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled = decoder(encoder(X[0:1].transpose(1,2).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled = sampled.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('out_pointnet.csv',sampled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
